import requests
from bs4 import BeautifulSoup
import pandas as pd

# 初始化列表，用于存储爬取到的数据
data = []

# 爬取前 30 页
for page in range(1, 31):
    print(f"正在爬取第 {page} 页...")
    url = f"https://sh.lianjia.com/ershoufang/pudong/pg{page}co32/"

    # 发送请求并获取页面内容
    response = requests.get(url)
    content = response.text

    # 使用 BeautifulSoup 解析页面
    soup = BeautifulSoup(content, "html.parser")

    # 获取房源列表
    house_list = soup.find_all("div", class_="info clear")

    # 提取房源数据
    for house in house_list:
        try:
            title = house.find("div", class_="title").a.string
        except AttributeError:
            title = None

        try:
            community_name = house.find("div", class_="positionInfo").a.string
        except AttributeError:
            community_name = None

        try:
            district = house.find("div", class_="positionInfo").find_all("a")[1].string
        except AttributeError:
            district = None

        try:
            total_price = house.find("div", class_="totalPrice").span.string
        except AttributeError:
            total_price = None

        try:
            unit_price = house.find("div", class_="unitPrice").span.string
        except AttributeError:
            unit_price = None

   
        # 将数据添加到列表
        data.append([title, community_name, district, total_price, unit_price])

# 使用 pandas 将数据转换为 DataFrame
columns = ['房源标题', '小区名称', '所在区', '总价', '单价']
df = pd.DataFrame(data, columns=columns)

# 将 DataFrame 写入 Excel 文件
df.to_excel('lianjia_ershoufang_data.xlsx', index=False)

print("数据已写入 Excel 文件：lianjia_ershoufang_data.xlsx")
